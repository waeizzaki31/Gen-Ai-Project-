{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "57cf3e72",
      "metadata": {
        "id": "57cf3e72"
      },
      "outputs": [],
      "source": [
        "# Step 1: Import necessary libraries\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.applications.resnet50 import preprocess_input, decode_predictions\n",
        "import numpy as np\n",
        "from transformers import pipeline\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "26a5b4f5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "26a5b4f5",
        "outputId": "aa6a3853-52a7-4a0f-f99b-39c8e0f53d3c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading image analysis model...\n"
          ]
        }
      ],
      "source": [
        "# Step 2: Load pre-trained ResNet50 model\n",
        "print(\"Loading image analysis model...\")\n",
        "model = ResNet50(weights='imagenet')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f9427d2d",
      "metadata": {
        "id": "f9427d2d"
      },
      "outputs": [],
      "source": [
        "# Step 3: Define a function to extract features from an image\n",
        "def extract_features(img_path):\n",
        "    \"\"\"\n",
        "    This function takes an image path, processes the image,\n",
        "    and predicts the top objects using ResNet50.\n",
        "    \"\"\"\n",
        "    print(f\"Processing image: {img_path}\")\n",
        "    img = image.load_img(img_path, target_size=(224, 224))\n",
        "    img_array = image.img_to_array(img)\n",
        "    img_array = np.expand_dims(img_array, axis=0)\n",
        "    img_array = preprocess_input(img_array)\n",
        "    predictions = model.predict(img_array)\n",
        "    decoded_predictions = decode_predictions(predictions, top=3)[0]\n",
        "    return decoded_predictions\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4d06c022",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4d06c022",
        "outputId": "a3dd6052-b5cf-4599-fb5a-f1314abc4b7a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading poetry generator model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "Device set to use cpu\n"
          ]
        }
      ],
      "source": [
        "# Step 4: Load a pre-trained language model for generating poetry\n",
        "print(\"Loading poetry generator model...\")\n",
        "poetry_generator = pipeline(\"text-generation\", model=\"gpt2\")\n",
        "\n",
        "def generate_poem(predictions):\n",
        "    \"\"\"\n",
        "    This function takes object predictions from the image\n",
        "    and generates a poem based on them.\n",
        "    \"\"\"\n",
        "    objects = \", \".join([pred[1] for pred in predictions])\n",
        "    prompt = f\"Write a beautiful poem about {objects}.\"\n",
        "    print(f\"Generating poem for: {objects}\")\n",
        "    poem = poetry_generator(prompt, max_length=50, num_return_sequences=1)\n",
        "    return poem[0][\"generated_text\"]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "390fb7c1",
      "metadata": {
        "id": "390fb7c1"
      },
      "outputs": [],
      "source": [
        "# Step 5: Main function to integrate everything\n",
        "def main():\n",
        "    \"\"\"\n",
        "    Main program to analyze an image and generate a poem.\n",
        "    \"\"\"\n",
        "    print(\"Welcome to the Image-to-Poem Generator!\")\n",
        "    img_path = \"/content/download.png\"\n",
        "    try:\n",
        "        predictions = extract_features(img_path)\n",
        "        print(\"Image analysis complete. Top predictions:\")\n",
        "        for i, pred in enumerate(predictions):\n",
        "            print(f\"{i+1}. {pred[1]} ({pred[2]*100:.2f}%)\")\n",
        "        poem = generate_poem(predictions)\n",
        "        print(\"\\nHere is your generated poem:\\n\")\n",
        "        print(poem)\n",
        "    except Exception as e:\n",
        "        print(\"An error occurred:\", e)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "702fc343",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "702fc343",
        "outputId": "68e4cb91-3e37-49f2-e1b5-d7b37a47d8e7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Welcome to the Image-to-Poem Generator!\n",
            "Processing image: /content/download.png\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image analysis complete. Top predictions:\n",
            "1. web_site (70.60%)\n",
            "2. menu (3.67%)\n",
            "3. envelope (1.68%)\n",
            "Generating poem for: web_site, menu, envelope\n",
            "\n",
            "Here is your generated poem:\n",
            "\n",
            "Write a beautiful poem about web_site, menu, envelope.\n",
            "\n",
            "And this is the only line I can remember…\n",
            "\n",
            "What are you on about?\n",
            "\n",
            "What have you done after that?\n",
            "\n",
            "I don't think you're\n"
          ]
        }
      ],
      "source": [
        "# Step 6: Run the program\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Xo8I3sbvYg_F"
      },
      "id": "Xo8I3sbvYg_F",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}